import numpy as np
import torch
import csv
import sys
from embedding import embed_sentence
import argparse

# Increase the CSV field size limit
# When I was reading/writing the speeches to an output file, the size of some of the speeches was too
# big to load, so I had to increase the size:
csv.field_size_limit(sys.maxsize)



def find_closest(matrix, vector, k=10):
    """
    This function uses euclidian distance to find the indices of the k closest
    rows in the input matrix to the input vector

    The indices are sorted in order of closest match

    Args:
        matrix (np.ndarray): The NumPy matrix (n_rows, n_features).
        vector (np.ndarray): The input vector (n_features,).
        k (int): The number of closest rows to return.

    Returns:
        List: The indices of the k closest rows in the original matrix.
    """
    # Store the distances,indices in a list of tuples:
    i = 0
    dist_list = []
    for row in matrix:
        distance = np.linalg.norm(row - vector)
        # Calculates Euclidean Distance
        # Source: https://www.geeksforgeeks.org/python/calculate-the-euclidean-distance-using-numpy/
        dist_list.append((distance,i))
        i += 1

    # Sort by distance:
    dist_list.sort()

    # select the k closest indices in order of distance (closest first)
    i_list = []
    for i in range(k):
        i_list.append(dist_list[i][1])

    return i_list





if __name__ == "__main__":
    # Argument parser
    parser = argparse.ArgumentParser(description="LMTester.py")
    parser.add_argument('-model', type=str, choices=['exorders','speeches'], default='exorders', help='Type of document to search')
    parser.add_argument('-output', type=str, choices=['newfile','stdout'], default='stdout', help='Location to send the output')

    # Parse the command-line arguments.
    args = parser.parse_args()
    print(args)

    # Set variables:
    results_file = 'search_results.tsv'
    num_rows_returned = 10
    if args.model == 'exorders':
        text_file = 'executive_orders.tsv'
        matrix_filename = 'executive_orders_matrix.npy'
    elif args.model == 'speeches':
        text_file = 'spoken_records.tsv'
        matrix_filename = 'speeches_matrix.npy'


    # Load the matrix from the .npy file
    loaded_matrix = np.load(matrix_filename) # Taken from google gen AI
    matrix_mean = np.mean(loaded_matrix, axis=0)
    matrix_stdev = np.std(loaded_matrix, axis=0)
    
    # Get an input and vectorize it:
    prompt = '''This is an executive order from the President of the United States.
The topic of the executive order is
''' # Above generated by ChatGPT

    search = input('Search: ')
    search = prompt + search

    search_vector = embed_sentence(search).cpu().detach().numpy()
    # Normalize the prompt so it falls in the same distribution as the input:
    search_vector = matrix_mean + (search_vector-matrix_mean)/matrix_stdev

    # Find indices of 10 closest:
    i_list = find_closest(loaded_matrix, search_vector, k=num_rows_returned)

    if args.output == 'newfile':
        # Loop through tsv file to find speeches at closest indices
        # This file was modified from a google AI generation
        with open(text_file, 'r', newline='', encoding='utf-8') as infile, open(results_file, 'w', newline='', encoding='utf-8') as outfile:

            reader = csv.reader(infile, delimiter='\t')
            writer = csv.writer(outfile, delimiter='\t')

            i = 0
            for row in reader:
                if i in i_list:
                    # writer.writerow(list((row[2],'')))
                    writer.writerow(row)
                i += 1
    else:
        with open(text_file, 'r', newline='', encoding='utf-8') as infile:

            reader = csv.reader(infile, delimiter='\t')

            i = 0
            for row in reader:
                if i in i_list:
                    
                    print('\t'.join(row))
                i += 1